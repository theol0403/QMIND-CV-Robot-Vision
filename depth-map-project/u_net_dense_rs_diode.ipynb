{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from data_generators import DiodeDataGenerator\n",
    "from data_generators import RsDiodeDataGenerator\n",
    "from diode import DIODE\n",
    "\n",
    "\n",
    "data_set_folder = \"/val/\"\n",
    "split = 'val'\n",
    "scene_type =  'indoors'\n",
    "meta_fname = './diode_meta.json'\n",
    "data_root = '/home/colin/projects/QMIND-CV-Robot-Vision/depth-map-project/data/'\n",
    "diode = DIODE(splits=split, scene_types=scene_type, meta_fname=meta_fname, data_root=data_root)\n",
    "\n",
    "# Ensure annotation folder exists\n",
    "if not os.path.exists(os.path.abspath(\"./data\") + data_set_folder):\n",
    "    annotation_zip = tf.keras.utils.get_file(\n",
    "        \"val.tar.gz\",\n",
    "        cache_subdir=os.path.abspath(\"./data\"),\n",
    "        origin=\"http://diode-dataset.s3.amazonaws.com/val.tar.gz\",\n",
    "        extract=True,\n",
    "    )\n",
    "\n",
    "dim = (256, 256, 3)\n",
    "tf.random.set_seed(123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D,  LeakyReLU, Concatenate, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class UpSamplingBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(UpSamplingBlock, self).__init__()\n",
    "        self.up_sampling = UpSampling2D(size=(2,2), interpolation='bilinear')\n",
    "        self.concat = Concatenate()\n",
    "        self.convA = Conv2D(filters=filters, kernel_size=(3,3), padding='same')\n",
    "        self.batch_normA = BatchNormalization()\n",
    "        self.reluA = LeakyReLU()\n",
    "        self.convB = Conv2D(filters=filters, kernel_size=(3,3), padding='same')\n",
    "        self.batch_normB = BatchNormalization()\n",
    "        self.reluB = LeakyReLU()   \n",
    "        \n",
    "    def call(self, input):\n",
    "        \"\"\" input is a 2 element list, first element is the input tensor, second element is the tensor to be concatenated from encoder\n",
    "        \"\"\"\n",
    "        x = self.up_sampling(input[0])\n",
    "        x = self.concat([x, input[1]])\n",
    "        x = self.convA(x)\n",
    "        x = self.batch_normA(x)\n",
    "        x = self.reluA(x)\n",
    "        x = self.convB(x)\n",
    "        x = self.batch_normB(x)\n",
    "        x = self.reluB(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim):\n",
    "        super(encoder, self).__init__()\n",
    "        self.dense_net = DenseNet201(input_shape=(dim[0], dim[1], 3), include_top=False, weights='imagenet') \n",
    "        for layer in self.dense_net.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        dense_net_layer_output_names = ['pool3_pool', 'pool2_pool', 'pool1','conv1/relu']\n",
    "        outputs = [self.dense_net.output]\n",
    "        for name in dense_net_layer_output_names:\n",
    "            outputs.append(self.dense_net.get_layer(name).output)\n",
    "\n",
    "        self.encoder = Model(inputs=self.dense_net.input, outputs=outputs)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.encoder(inputs)\n",
    "    \n",
    "\n",
    "class decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.covA = Conv2D(filters=1664, kernel_size=(1,1), padding='same')\n",
    "        self.up_block1 = UpSamplingBlock(filters=832)\n",
    "        self.up_block2 = UpSamplingBlock(filters=416)\n",
    "        self.up_block3 = UpSamplingBlock(filters=208)\n",
    "        self.up_block4 = UpSamplingBlock(filters=104)\n",
    "        self.covB = Conv2D(filters=1, activation=\"sigmoid\", kernel_size=(3,3), padding='same')\n",
    "\n",
    "    def call(self, features):\n",
    "        x = self.covA(features[0])\n",
    "        x = self.up_block1([x, features[1]])\n",
    "        x = self.up_block2([x, features[2]])\n",
    "        x = self.up_block3([x, features[3]])\n",
    "        x = self.up_block4([x, features[4]])\n",
    "        x = self.covB(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class DepthEstimator(tf.keras.Model):\n",
    "    def __init__(self, dim):\n",
    "        super(DepthEstimator, self).__init__()\n",
    "        self.encoder = encoder(dim)\n",
    "        self.decoder = decoder()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.encoder(inputs)\n",
    "        depth = self.decoder(features)\n",
    "        return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39mloss_function, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     34\u001b[0m custom_data_generator \u001b[38;5;241m=\u001b[39m RsDiodeDataGenerator(diode_split\u001b[38;5;241m=\u001b[39msplit, diode_scene_type\u001b[38;5;241m=\u001b[39mscene_type, diode_meta_name\u001b[38;5;241m=\u001b[39mmeta_fname, data_root\u001b[38;5;241m=\u001b[39mdata_root, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[0;32m---> 37\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(custom_data_generator,epochs\u001b[38;5;241m=\u001b[39mepochs, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(args, kwds, add_initializers_to\u001b[38;5;241m=\u001b[39minitializers)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mtrace_function(\n\u001b[1;32m    696\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    697\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[38;5;241m=\u001b[39mfunction_type_utils\u001b[38;5;241m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m api\u001b[38;5;241m.\u001b[39mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[38;5;241m=\u001b[39mconverter\u001b[38;5;241m.\u001b[39mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[38;5;241m=\u001b[39mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqdiyjevo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(run_step, args\u001b[38;5;241m=\u001b[39m(data,))\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended\u001b[38;5;241m.\u001b[39mcall_for_each_replica(fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(data)\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/engine/training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow_addons/optimizers/weight_decay_optimizers.py:168\u001b[0m, in \u001b[0;36mDecoupledWeightDecayExtension.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, decay_var_list, tape)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    ValueError: If some of the variables are not `Variable` objects.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_decay_var_list(var_list, decay_var_list)\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    169\u001b[0m     loss, var_list\u001b[38;5;241m=\u001b[39mvar_list, grad_loss\u001b[38;5;241m=\u001b[39mgrad_loss, name\u001b[38;5;241m=\u001b[39mname, tape\u001b[38;5;241m=\u001b[39mtape\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:598\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    568\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_gradients(\n\u001b[1;32m    599\u001b[0m         loss, var_list\u001b[38;5;241m=\u001b[39mvar_list, grad_loss\u001b[38;5;241m=\u001b[39mgrad_loss, tape\u001b[38;5;241m=\u001b[39mtape\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:656\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    654\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 656\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradients(\n\u001b[1;32m    657\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes(\n\u001b[1;32m    661\u001b[0m     [\n\u001b[1;32m    662\u001b[0m         v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     ]\n\u001b[1;32m    666\u001b[0m )\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:532\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    531\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, var_list, grad_loss)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m imperative_grad\u001b[38;5;241m.\u001b[39mimperative_grad(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape,\n\u001b[1;32m   1068\u001b[0m     flat_targets,\n\u001b[1;32m   1069\u001b[0m     flat_sources,\n\u001b[1;32m   1070\u001b[0m     output_gradients\u001b[38;5;241m=\u001b[39moutput_gradients,\n\u001b[1;32m   1071\u001b[0m     sources_raw\u001b[38;5;241m=\u001b[39mflat_sources_raw,\n\u001b[1;32m   1072\u001b[0m     unconnected_gradients\u001b[38;5;241m=\u001b[39munconnected_gradients)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_tape,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str(unconnected_gradients\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/ops/nn_grad.py:594\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    575\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    584\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_input(\n\u001b[1;32m    585\u001b[0m         shape_0,\n\u001b[1;32m    586\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    587\u001b[0m         grad,\n\u001b[1;32m    588\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m    589\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m    590\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    591\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    592\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    593\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format),\n\u001b[0;32m--> 594\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_filter(\n\u001b[1;32m    595\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    596\u001b[0m         shape_1,\n\u001b[1;32m    597\u001b[0m         grad,\n\u001b[1;32m    598\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m    599\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m    600\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    601\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m    602\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m    603\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format)\n\u001b[1;32m    604\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/ops/gen_nn_ops.py:1536\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1532\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1533\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected list for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2d_backprop_filter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dilations)\n\u001b[1;32m   1535\u001b[0m dilations \u001b[38;5;241m=\u001b[39m [_execute\u001b[38;5;241m.\u001b[39mmake_int(_i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m dilations]\n\u001b[0;32m-> 1536\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m _op_def_library\u001b[38;5;241m.\u001b[39m_apply_op_helper(\n\u001b[1;32m   1537\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv2DBackpropFilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, filter_sizes\u001b[38;5;241m=\u001b[39mfilter_sizes,\n\u001b[1;32m   1538\u001b[0m                               out_backprop\u001b[38;5;241m=\u001b[39mout_backprop, strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m   1539\u001b[0m                               padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   1540\u001b[0m                               use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[1;32m   1541\u001b[0m                               explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[1;32m   1542\u001b[0m                               data_format\u001b[38;5;241m=\u001b[39mdata_format, dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[1;32m   1543\u001b[0m                               name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1544\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    792\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    794\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    795\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m   op \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39m_create_op_internal(op_type_name, inputs, dtypes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    797\u001b[0m                              name\u001b[38;5;241m=\u001b[39mscope, input_types\u001b[38;5;241m=\u001b[39minput_types,\n\u001b[1;32m    798\u001b[0m                              attrs\u001b[38;5;241m=\u001b[39mattr_protos, op_def\u001b[38;5;241m=\u001b[39mop_def)\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 2652\u001b[0m   ret \u001b[38;5;241m=\u001b[39m Operation\u001b[38;5;241m.\u001b[39mfrom_node_def(\n\u001b[1;32m   2653\u001b[0m       node_def,\n\u001b[1;32m   2654\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2655\u001b[0m       inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m   2656\u001b[0m       output_types\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[1;32m   2657\u001b[0m       control_inputs\u001b[38;5;241m=\u001b[39mcontrol_inputs,\n\u001b[1;32m   2658\u001b[0m       input_types\u001b[38;5;241m=\u001b[39minput_types,\n\u001b[1;32m   2659\u001b[0m       original_op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_original_op,\n\u001b[1;32m   2660\u001b[0m       op_def\u001b[38;5;241m=\u001b[39mop_def,\n\u001b[1;32m   2661\u001b[0m   )\n\u001b[1;32m   2662\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   2663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m c_op \u001b[38;5;241m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[38;5;241m=\u001b[39mop_def)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1026\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n\u001b[1;32m   1025\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetOpStackTrace(\n\u001b[0;32m-> 1026\u001b[0m       c_op, tf_stack\u001b[38;5;241m.\u001b[39mextract_stack(stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m   1027\u001b[0m   )\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "File \u001b[0;32m~/anaconda3/envs/QMIND101/lib/python3.11/site-packages/tensorflow/python/util/tf_stack.py:162\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"An eager-friendly alternative to traceback.extract_stack.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m  line, meant to masquerade as traceback.FrameSummary objects.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m thread_key \u001b[38;5;241m=\u001b[39m _get_thread_key()\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_stack\u001b[38;5;241m.\u001b[39mextract_stack(\n\u001b[1;32m    163\u001b[0m     _source_mapper_stacks[thread_key][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39minternal_map,\n\u001b[1;32m    164\u001b[0m     _source_filter_stacks[thread_key][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39minternal_set,\n\u001b[1;32m    165\u001b[0m     stacklevel,\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# build and train the model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "\n",
    "  #Cosine distance loss\n",
    "  depth_loss = tf.reduce_mean(K.abs(y_pred - y_true), axis=-1)\n",
    "  \n",
    "  # edge loss for sharp edges\n",
    "  dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "  dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "  grad_loss = tf.reduce_mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "  \n",
    "  # structural similarity loss assuming target range is 1\n",
    "  ssim_loss = tf.clip_by_value((1 - tf.image.ssim(y_true, y_pred, 1.0)) * 0.5, 0, 1)\n",
    "\n",
    "  # weightage\n",
    "  depth_loss_weight = 0.1\n",
    "  return ssim_loss + tf.reduce_mean(grad_loss) + depth_loss_weight * tf.reduce_mean(depth_loss)\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "lr = 0.0001\n",
    "\n",
    "# Create the model\n",
    "model = DepthEstimator(dim)\n",
    "opt = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=1e-6,amsgrad=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "custom_data_generator = RsDiodeDataGenerator(diode_split=split, diode_scene_type=scene_type, diode_meta_name=meta_fname, data_root=data_root, batch_size=batch_size, dim=dim)\n",
    "\n",
    "\n",
    "model.fit(custom_data_generator,epochs=epochs, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DiodeDataGenerator.pre_process_depth() missing 1 required positional argument: 'flip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m x, y, _\u001b[38;5;241m=\u001b[39m custom_data_generator\u001b[38;5;241m.\u001b[39mload(i)\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m custom_data_generator\u001b[38;5;241m.\u001b[39mpre_process_image(x, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m y \u001b[38;5;241m=\u001b[39m custom_data_generator\u001b[38;5;241m.\u001b[39mpre_process_depth(y, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Predict depth map\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DiodeDataGenerator.pre_process_depth() missing 1 required positional argument: 'flip'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the results\n",
    "\n",
    "num_tests = 50\n",
    "custom_data_generator = DiodeDataGenerator(split=\"val\", scene_types=scene_type, meta_fname=meta_fname, data_root=data_root, batch_size=1, dim=dim)\n",
    "\n",
    "# Load and predict images one by one\n",
    "for i in range(num_tests):\n",
    "    _, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 20))  # Adjust as needed\n",
    "\n",
    "\n",
    "    x, y, _= custom_data_generator.load(i)\n",
    "    x = custom_data_generator.pre_process_image(x, False)\n",
    "    y = custom_data_generator.pre_process_depth(y, False)\n",
    "    \n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Predict depth map\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    # Plot original image, truth depth map, and predicted depth map using matplotlib\n",
    "    axs[0].imshow(x[0])\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[1].imshow(y)\n",
    "    axs[1].set_title('Truth Depth Map')\n",
    "    axs[2].imshow(y_pred[0, :, :, 0])\n",
    "    axs[2].set_title('Predicted Depth Map')\n",
    "\n",
    "    # Remove axis for all subplots\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QMIND2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
